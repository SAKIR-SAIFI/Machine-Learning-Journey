{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37b4779-fa35-4529-bf5b-ef5f51df4a72",
   "metadata": {},
   "source": [
    "IRIS DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47b2dd-a0ed-4051-882d-710afc7e4e7e",
   "metadata": {},
   "source": [
    "The Iris dataset is one of the most famous datasets used for machine learning and data analysis. It was introduced by the British statistician and biologist Ronald Fisher in 1936. The dataset is simple and widely used for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900a472-2154-4c11-aab2-4fa7c5a7af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Features of the Iris Dataset:\n",
    "# Data Description:\n",
    "\n",
    "# The dataset contains 150 samples of iris flowers.\n",
    "# It includes measurements for four features of the flowers:\n",
    "# Sepal length (in cm)\n",
    "# Sepal width (in cm)\n",
    "# Petal length (in cm)\n",
    "# Petal width (in cm)\n",
    "# Classes (Target Variable):\n",
    "\n",
    "# There are three species of Iris flowers in the dataset:\n",
    "# Iris-setosa\n",
    "# Iris-versicolor\n",
    "# Iris-virginica\n",
    "# Each species has 50 samples.\n",
    "# Type of Problem:\n",
    "\n",
    "# It is a multiclass classification problem where the goal is to classify the iris flower species based on the given features.\n",
    "# Balanced Dataset:\n",
    "\n",
    "# The dataset is balanced, meaning each class has the same number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cb216e0-3a0d-49b4-9cc3-7d2a12c55a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "  species  \n",
      "0  setosa  \n",
      "1  setosa  \n",
      "2  setosa  \n",
      "3  setosa  \n",
      "4  setosa  \n"
     ]
    }
   ],
   "source": [
    "# Code Example (Using Python):\n",
    "# Here's an example of how to load and explore the Iris dataset using Python's scikit-learn library:\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data['species'] = iris.target\n",
    "\n",
    "# Mapping numeric species to actual names\n",
    "data['species'] = data['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673aa137-0d52-40f1-9ff3-ee798f922891",
   "metadata": {},
   "source": [
    "Lets make a simple MAchine Learning Model using Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e29af-c249-4e0f-b1e9-62739773daab",
   "metadata": {},
   "source": [
    "Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "902db510-7bbb-4e68-b71f-52050ac28860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report , confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af733985-3ec0-46ea-8f75-148359e9b895",
   "metadata": {},
   "source": [
    "Step 2: Load and Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4144b-c1b1-4649-9f7e-26db81449b61",
   "metadata": {},
   "source": [
    "For this example, we’ll use the Iris dataset, a classic dataset for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1441e7fd-1bdf-4655-8558-d5d04f40c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target Names:  ['setosa' 'versicolor' 'virginica']\n",
      "First 5 Rows of Data:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "Target Labels:\n",
      " [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data   #features\n",
    "Y = iris.target  #labels\n",
    "\n",
    "#check the dataset\n",
    "print(\"Feature Names: \", iris.feature_names)\n",
    "print(\"Target Names: \", iris.target_names)\n",
    "print(\"First 5 Rows of Data:\\n\",X[:5])\n",
    "print(\"Target Labels:\\n\",Y[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7e168-8a85-4717-8716-1b539b33db86",
   "metadata": {},
   "source": [
    "Step 3: Split the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3877de-3102-4e4d-88e9-72c36284628d",
   "metadata": {},
   "source": [
    "We split the dataset into training and testing sets to evaluate the model’s performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7c0dfc-ad57-4c55-8680-644b317bd7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size:  105\n",
      "Testing Set Size:  45\n"
     ]
    }
   ],
   "source": [
    "#Split into training and testing sets\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3,random_state = 42)\n",
    "\n",
    "print(\"Training Set Size: \",len(X_train))\n",
    "print(\"Testing Set Size: \",len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d59de-b7ff-4581-a76b-1a5261cbd465",
   "metadata": {},
   "source": [
    "Step 4: Train the Model\n",
    "We’ll use a Logistic Regression model for this classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf6ec62-8584-4db7-b579-052728f5adae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter = 200)\n",
    "model.fit(X_train,Y_train)\n",
    "print(\"Model Trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf212e-7897-4ad3-b9af-5de09f3d6cc4",
   "metadata": {},
   "source": [
    "Step 5: Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f80ce-226d-4807-bdcd-52fb97c96032",
   "metadata": {},
   "source": [
    "Predict on the test set and check how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23cfb76d-2b4b-4d2d-810e-2622a87ef4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels:  [1 0 2 1 1 0 1 2 1 1]\n",
      "Actual Labels:  [1 0 2 1 1 0 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "#make predictions\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Predicted Labels: \",Y_pred[:10])\n",
    "print(\"Actual Labels: \",Y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1eaccb-f9de-41e4-816a-e288f0783f89",
   "metadata": {},
   "source": [
    "Step 6: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25650f-d3da-44a0-af8b-aa259a163a78",
   "metadata": {},
   "source": [
    "We’ll use accuracy, confusion matrix, and a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84daa808-829a-42c4-ad8b-726cfb2a114a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  1.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "accuracy = accuracy_score(Y_test,Y_pred)\n",
    "print(\"\\nAccuracy: \", accuracy)\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "#Classification Report\n",
    "report = classification_report(Y_test,Y_pred,target_names = iris.target_names)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927e268-65df-420f-9128-64691c0ec1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
